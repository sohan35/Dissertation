{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8825c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Available Crime Types:\n",
      "['Theft (Auto Theft)' 'Theft (House Theft)' 'Theft (HBT Night)'\n",
      " 'Assault (Hurt)' 'Drug Related (NDPS)' 'Theft (Chain Snatching)'\n",
      " 'Theft (HBT Day)' 'Assault (Hurt) ' 'Drug Related (NDPS) '\n",
      " 'Theft (Robbery)' 'Theft (other  Theft )']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Interpreted crime type as: Assault (Hurt)\n",
      "\n",
      "üìç Police Station with most cases: Anjuna_Ps (107 cases)\n",
      "üìå Location type with most crime: InHouse (44 cases)\n",
      "\n",
      "üöì Police Allocation for Anjuna_Ps (Total Crimes: 107):\n",
      "  ClubArea: 9 officers\n",
      "  localArea: 9 officers\n",
      "  ResidentialArea: 7 officers\n",
      "  LocalArea: 6 officers\n",
      "\n",
      "üöì Police Allocation for Mapusa_Ps (Total Crimes: 80):\n",
      "  ResidentialArea: 11 officers\n",
      "  ReligiousPlace: 8 officers\n",
      "  LocalArea: 7 officers\n",
      "  MarketZone: 6 officers\n",
      "\n",
      "üöì Police Allocation for Colvale_PS (Total Crimes: 45):\n",
      "  LocalArea: 11 officers\n",
      "  ResidentialArea: 10 officers\n",
      "  IndustrialArea: 6 officers\n",
      "  Business/Store: 4 officers\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"sy.csv\", encoding='latin1')\n",
    "\n",
    "# --- Step 1: Clean and Prepare Geo_Location ---\n",
    "df['Geo_Location'] = df['Geo_Location'].str.replace('(', '', regex=False).str.replace(')', '', regex=False).str.strip()\n",
    "df[['Latitude', 'Longitude']] = df['Geo_Location'].str.split(',', expand=True)\n",
    "df['Latitude'] = df['Latitude'].astype(float)\n",
    "df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "# Encode Crime_Location_Type (optional for clustering logic)\n",
    "le = LabelEncoder()\n",
    "df['Crime_Location_Encoded'] = le.fit_transform(df['Crime_Location_Type'])\n",
    "\n",
    "# --- Step 2: Police Deployment Based on Crime Type and Crime_Location_Type ---\n",
    "df['Head_clean'] = df['Head'].str.lower().str.strip()\n",
    "\n",
    "# Display crime types\n",
    "print(\"\\n‚úÖ Available Crime Types:\")\n",
    "print(df['Head'].dropna().unique())\n",
    "\n",
    "# Input crime type\n",
    "user_crime_input = input(\"Enter a crime type: \").lower().strip()\n",
    "\n",
    "# Match crime\n",
    "matched_crime = None\n",
    "for crime in df['Head_clean'].unique():\n",
    "    if user_crime_input in crime:\n",
    "        matched_crime = crime\n",
    "        break\n",
    "\n",
    "if not matched_crime:\n",
    "    print(\"‚ùå No matching crime type found.\")\n",
    "else:\n",
    "    filtered_crime_df = df[df['Head_clean'] == matched_crime]\n",
    "    matched_display = df[df['Head_clean'] == matched_crime]['Head'].iloc[0]\n",
    "    print(f\"\\n‚úÖ Interpreted crime type as: {matched_display}\")\n",
    "\n",
    "    top_station = filtered_crime_df['Police Station'].value_counts().idxmax()\n",
    "    top_station_cases = filtered_crime_df['Police Station'].value_counts().max()\n",
    "    top_location = filtered_crime_df['Crime_Location_Type'].value_counts().idxmax()\n",
    "    top_location_cases = filtered_crime_df['Crime_Location_Type'].value_counts().max()\n",
    "\n",
    "    print(f\"\\nüìç Police Station with most cases: {top_station} ({top_station_cases} cases)\")\n",
    "    print(f\"üìå Location type with most crime: {top_location} ({top_location_cases} cases)\")\n",
    "\n",
    "    fixed_police_per_station = 50\n",
    "    excluded_locations = ['InHouse']  # Add more if needed\n",
    "\n",
    "    for station in df['Police Station'].unique():\n",
    "        station_df = filtered_crime_df[filtered_crime_df['Police Station'] == station]\n",
    "\n",
    "        if station_df.empty:\n",
    "            print(f\"\\nüöì Police Allocation for {station} (Total Crimes: 0):\")\n",
    "            print(\"  No crimes of this type reported. Allocate minimum patrol if needed.\")\n",
    "            continue\n",
    "\n",
    "        location_counts = station_df['Crime_Location_Type'].value_counts().to_dict()\n",
    "        total_crimes = sum(location_counts.values())\n",
    "\n",
    "        print(f\"\\nüöì Police Allocation for {station} (Total Crimes: {total_crimes}):\")\n",
    "\n",
    "        # Remove excluded locations like 'InHouse'\n",
    "        deployable_locations = {\n",
    "            loc: count for loc, count in location_counts.items() if loc not in excluded_locations\n",
    "        }\n",
    "\n",
    "        if not deployable_locations:\n",
    "            print(\"  ‚ö†Ô∏è All reported crimes are in non-deployable areas like houses. Assign general patrolling if needed.\")\n",
    "            continue\n",
    "\n",
    "        # Get top 4 deployable locations\n",
    "        top_locations = dict(sorted(deployable_locations.items(), key=lambda item: item[1], reverse=True)[:4])\n",
    "\n",
    "        for location_type, count in top_locations.items():\n",
    "            percent = count / total_crimes\n",
    "            officers_assigned = round(percent * fixed_police_per_station)\n",
    "            print(f\"  {location_type}: {officers_assigned} officers\")\n",
    "\n",
    "    # --- Step 3: Optional Clustering Without Visualization ---\n",
    "    clustering_df = filtered_crime_df.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "    if not clustering_df.empty and len(clustering_df) >= 3:\n",
    "        coords = clustering_df[['Latitude', 'Longitude']]\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        clustering_df['Cluster'] = kmeans.fit_predict(coords)\n",
    "\n",
    "        # You can use clustering_df['Cluster'] for further logic if needed\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Not enough data with coordinates to perform clustering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d2aaf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Crime Types:\n",
      "['Theft (Auto Theft)' 'Theft (House Theft)' 'Theft (HBT Night)'\n",
      " 'Assault (Hurt)' 'Drug Related (NDPS)' 'Theft (Chain Snatching)'\n",
      " 'Theft (HBT Day)' 'Theft (Robbery)' 'Theft (other Theft )']\n",
      "\n",
      "Interpreted crime type as: Theft (HBT Day)\n",
      "\n",
      "Police Station with most cases: Mapusa_Ps (16 cases)\n",
      "Location type with most crime: InHouse (11 cases)\n",
      "\n",
      "Police Allocation for Anjuna_Ps:\n",
      "  InHouse: Investigate on a case-by-case basis. No direct deployment.\n",
      "  ResidentialArea: Moderate staff deployment recommended.\n",
      "  Peak Months: July\n",
      "\n",
      "Police Allocation for Mapusa_Ps:\n",
      "  InHouse: Investigate on a case-by-case basis. No direct deployment.\n",
      "  ReligiousPlace: Moderate staff deployment recommended.\n",
      "  ParkingLot: Fewer staff required.\n",
      "  MarketZone: Fewer staff required.\n",
      "  Peak Months: July, June, April\n",
      "\n",
      "Police Allocation for Colvale_PS:\n",
      "  ResidentialArea: More staff should be deployed.\n",
      "  ParkingLot: More staff should be deployed.\n",
      "  NearCollege: Moderate staff deployment recommended.\n",
      "  LocalArea: Moderate staff deployment recommended.\n",
      "  Peak Months: April\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sy.csv\", encoding='latin1')\n",
    "\n",
    "# Clean and prepare Geo_Location\n",
    "df['Geo_Location'] = df['Geo_Location'].str.replace('(', '', regex=False).str.replace(')', '', regex=False).str.strip()\n",
    "df[['Latitude', 'Longitude']] = df['Geo_Location'].str.split(',', expand=True)\n",
    "df['Latitude'] = df['Latitude'].astype(float)\n",
    "df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "# Extract Month from Date\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Month'] = df['Date'].dt.month_name()\n",
    "\n",
    "# Encode for clustering\n",
    "le = LabelEncoder()\n",
    "df['Crime_Location_Encoded'] = le.fit_transform(df['Crime_Location_Type'])\n",
    "\n",
    "# Clean crime type names\n",
    "df['Head'] = df['Head'].astype(str).str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "df['Head_clean'] = df['Head'].str.lower().str.strip()\n",
    "\n",
    "# Display available crime types\n",
    "print(\"\\nAvailable Crime Types:\")\n",
    "print(df['Head'].dropna().unique())\n",
    "\n",
    "# Input crime type\n",
    "user_crime_input = input(\"Enter a crime type: \").lower().strip()\n",
    "\n",
    "# Match crime\n",
    "matched_crime = None\n",
    "for crime in df['Head_clean'].unique():\n",
    "    if user_crime_input in crime:\n",
    "        matched_crime = crime\n",
    "        break\n",
    "\n",
    "if not matched_crime:\n",
    "    print(\"No matching crime type found.\")\n",
    "else:\n",
    "    filtered_crime_df = df[df['Head_clean'] == matched_crime]\n",
    "    matched_display = df[df['Head_clean'] == matched_crime]['Head'].iloc[0]\n",
    "    print(f\"\\nInterpreted crime type as: {matched_display}\")\n",
    "\n",
    "    top_station = filtered_crime_df['Police Station'].value_counts().idxmax()\n",
    "    top_station_cases = filtered_crime_df['Police Station'].value_counts().max()\n",
    "    top_location = filtered_crime_df['Crime_Location_Type'].value_counts().idxmax()\n",
    "    top_location_cases = filtered_crime_df['Crime_Location_Type'].value_counts().max()\n",
    "\n",
    "    print(f\"\\nPolice Station with most cases: {top_station} ({top_station_cases} cases)\")\n",
    "    print(f\"Location type with most crime: {top_location} ({top_location_cases} cases)\")\n",
    "\n",
    "    for station in df['Police Station'].unique():\n",
    "        station_df = filtered_crime_df[filtered_crime_df['Police Station'] == station]\n",
    "\n",
    "        print(f\"\\nPolice Allocation for {station}:\")\n",
    "\n",
    "        if station_df.empty:\n",
    "            print(\"  No crimes of this type reported. Allocate minimum patrol if needed.\")\n",
    "            continue\n",
    "\n",
    "        location_counts = station_df['Crime_Location_Type'].value_counts()\n",
    "        total_crimes = location_counts.sum()\n",
    "\n",
    "        top_locations = dict(sorted(location_counts.items(), key=lambda x: x[1], reverse=True)[:4])\n",
    "\n",
    "        for location_type, count in top_locations.items():\n",
    "            if location_type.strip().lower() == 'inhouse':\n",
    "                print(f\"  {location_type}: Investigate on a case-by-case basis. No direct deployment.\")\n",
    "            else:\n",
    "                percent = count / total_crimes\n",
    "                if percent >= 0.3:\n",
    "                    print(f\"  {location_type}: More staff should be deployed.\")\n",
    "                elif 0.1 <= percent < 0.3:\n",
    "                    print(f\"  {location_type}: Moderate staff deployment recommended.\")\n",
    "                else:\n",
    "                    print(f\"  {location_type}: Fewer staff required.\")\n",
    "\n",
    "        # Peak months analysis\n",
    "        top_months = (\n",
    "            station_df['Month'].value_counts().head(3).index.tolist()\n",
    "        )\n",
    "        if top_months:\n",
    "            print(\"  Peak Months:\", ', '.join(top_months))\n",
    "\n",
    "    # Clustering logic\n",
    "    clustering_df = filtered_crime_df.dropna(subset=['Latitude', 'Longitude'])\n",
    "    if not clustering_df.empty and len(clustering_df) >= 3:\n",
    "        coords = clustering_df[['Latitude', 'Longitude']]\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        clustering_df['Cluster'] = kmeans.fit_predict(coords)\n",
    "        # You can use clustering_df['Cluster'] for further logic\n",
    "    else:\n",
    "        print(\"\\nNot enough data with coordinates to perform clustering.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
